import os
import click
import asyncio
import pandas as pd
from scraper import search_google
from cache import Cache
from rich.console import Console
from rich.progress import Progress, track
from rich.live import Live
from rich.table import Table
from rich.progress import BarColumn, TimeElapsedColumn, SpinnerColumn
from urllib.parse import urlparse, urlunparse

console = Console()

# Mapowanie platform spo≈Çeczno≈õciowych na domeny
DOMAIN_MAP = {
    'Instagram': 'instagram.com',
    'TikTok': 'tiktok.com',
    'Facebook': 'facebook.com',
    'YouTube': 'youtube.com',
    'UberEats': 'ubereats.com',
    'TripAdvisor': 'tripadvisor.com',
    'TheFork': 'thefork.com'
}

# Budowanie zapytania na podstawie nazwy baru i lokalizacji
def build_query(bar_name, location):
    return f"{bar_name} {location}"

# Funkcja czyszczƒÖca URL z niepotrzebnych parametr√≥w
def clean_url(url):
    parsed_url = urlparse(url)
    clean_url = urlunparse(parsed_url._replace(query=''))  # Usuwamy parametry z URL-a
    return clean_url

# Dynamiczne monitorowanie zada≈Ñ asyncio
async def process_missing_data(df, cache, verbose):
    tasks = []
    found_count = 0
    missing_count = 0

    # Przygotowanie progresu i tabeli do wy≈õwietlania w konsoli
    progress = Progress(
        SpinnerColumn(),  
        "[progress.description]{task.description}",
        BarColumn(),
        "[progress.percentage]{task.percentage:>3.1f}%",
        TimeElapsedColumn()
    )
    task_id = progress.add_task("[green]Przetwarzanie danych...", total=len(df))

    # Tabela dla wynik√≥w wyszukiwania
    table = Table(title="Status zada≈Ñ async")
    table.add_column("Nazwa", justify="left")
    table.add_column("Platforma", justify="left")
    table.add_column("Status", justify="right")

    live_table = Live(table, console=console, refresh_per_second=4)

    # Konwertujemy kolumny na typ str, aby uniknƒÖƒá ostrze≈ºe≈Ñ o niezgodnych typach
    for platform in DOMAIN_MAP.keys():
        if platform in df.columns:
            df[platform] = df[platform].astype(str)

    with progress, live_table:
        for index, row in df.iterrows():
            # Budowanie zapytania na podstawie nazwy i lokalizacji
            restaurant_name = row['Name']
            location = row['Location']
            query = build_query(restaurant_name, location)

            if verbose:
                console.log(f"üöÄ Rozpoczƒôcie wyszukiwania dla: {query}")
            
            task = search_google(query, verbose)
            tasks.append((task, index, restaurant_name))

        results = await asyncio.gather(*[task for task, _, _ in tasks], return_exceptions=True)

        for i, (result, index, restaurant_name) in enumerate(zip(results, [index for _, index, _ in tasks], 
                                                                 [restaurant_name for _, _, restaurant_name in tasks])):
            if isinstance(result, Exception):
                missing_count += 1
                table.add_row(restaurant_name, "Wszystkie platformy", "[red]B≈ÇƒÖd[/red]")
                if verbose:
                    console.log(f"[bold red]‚ùå WystƒÖpi≈Ç b≈ÇƒÖd podczas wyszukiwania dla '{restaurant_name}': {result}[/bold red]")
            else:
                found_count += 1

                # Wy≈õwietlanie wyniku w zwiƒôz≈Çy spos√≥b
                if verbose:
                    console.log(f"üîç Wynik wyszukiwania dla '{restaurant_name}' zako≈Ñczony pomy≈õlnie.")

                # Czyszczenie URL-i z niepotrzebnych parametr√≥w i aktualizacja tabeli
                for platform in DOMAIN_MAP.keys():
                    platform_key = platform.lower()
                    if result.get(platform_key):
                        clean_link = clean_url(result[platform_key])  # Usuniƒôcie zbƒôdnych parametr√≥w
                        df.at[index, platform] = clean_link
                        table.add_row(restaurant_name, platform, "[green]Zako≈Ñczono[/green]")

            progress.update(task_id, advance=1)
            await asyncio.sleep(0.1)

    return df, found_count, missing_count

# Dodajemy CLI przy pomocy Click
@click.command()
@click.option('--input_file', required=True, help='≈öcie≈ºka do pliku CSV z danymi.')
@click.option('--output_file', default='output.csv', help='≈öcie≈ºka do pliku, gdzie zapisane zostanƒÖ zaktualizowane dane.')
@click.option('--use_cache', is_flag=True, help='Czy u≈ºywaƒá cache do przyspieszenia wyszukiwa≈Ñ?')
@click.option('--verbose', is_flag=True, help='Wy≈õwietlaj szczeg√≥≈Çowe informacje o przebiegu.')
@click.option('--social', is_flag=True, help='Uzupe≈Çniaj brakujƒÖce profile spo≈Çeczno≈õciowe.')
def main(input_file, output_file, use_cache, verbose, social):
    """
    Skrypt uzupe≈Çnia brakujƒÖce dane w pliku CSV poprzez wyszukiwanie informacji na Google.
    Plik CSV nale≈ºy zapodaƒá przez --input_file, a wynik zostanie zapisany w --output_file.
    """
    
    # Sprawdzamy, czy podano flagƒô --social
    if not social:
        console.print("[bold red]‚ùå Nie wybrano funkcji. U≈ºyj --help, aby zobaczyƒá dostƒôpne opcje.[/bold red]")
        # Wy≈õwietlenie standardowego helpa
        click.echo(main.get_help(click.Context(main)))
        return

    # ≈Åadowanie pliku CSV
    try:
        df = pd.read_csv(input_file)
        console.print(f"[bold green]‚úÖ Wczytano plik {input_file}.[/bold green]")
    except FileNotFoundError:
        console.print(f"[bold red]‚ùå Plik {input_file} nie zosta≈Ç znaleziony.[/bold red]")
        return

    if verbose:
        console.print(f"[bold green]‚ÑπÔ∏è U≈ºywanie cache: {use_cache}[/bold green]" if use_cache else "[bold yellow]‚ö†Ô∏è Cache nie u≈ºywany[/bold yellow]")

    # ≈Åadowanie cache
    cache = Cache() if use_cache else None

    # Przetwarzanie brakujƒÖcych danych
    updated_df, found_count, missing_count = asyncio.run(process_missing_data(df, cache, verbose))

    # Zapisanie zaktualizowanego pliku CSV
    output_dir = os.path.dirname(output_file)
    if output_dir and not os.path.exists(output_dir):
        try:
            os.makedirs(output_dir, exist_ok=True)  # U≈ºywamy exist_ok=True, aby zapobiec b≈Çƒôdom
        except OSError as exc:
            console.print(f"[bold red]‚ùå B≈ÇƒÖd podczas tworzenia katalogu: {exc}[/bold red]")
            return
    
    updated_df.to_csv(output_file, index=False)
    console.print(f"[bold green]‚úÖ Zapisano zaktualizowany plik CSV w {output_file}.[/bold green]")

    if cache:
        cache.save_cache()

    if verbose:
        console.print(f"[bold green]‚úÖ Przetworzono {found_count} znalezionych rekord√≥w i {missing_count} brakujƒÖcych.[/bold green]")
    else:
        console.print(f"[bold blue]‚ÑπÔ∏è Przetworzono rekordy: {found_count} znalezionych, {missing_count} brakujƒÖcych.[/bold blue]")

if __name__ == "__main__":
    main()